---
title: "Validating some Beliefs about Income Bias"
author: "David Pinto"
date: "March 31, 2017"
output: 
   html_document: 
     keep_md: yes
     theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, 
                      warning = FALSE, fig.align = "center")
```

## Introduction

In this kernel we will use `tidyverse` to validade some popular hypothesis about bias in income. Then we will fit some machine learning models to get more accurated answers.

Some analyses presented here are based on the book [Mastering Python for Data Science](https://www.amazon.com/Mastering-Python-Science-Samir-Madhavan/dp/1784390151).

So, let's get started!

## Load Required Packages

We will need the following `R` packages:

```{r}
library(readr)   # To import data
library(tidyr)   # To clean and format data
library(dplyr)   # To manipulate data
library(purrr)   # To do functional programming
library(ggplot2) # To visualize data
library(caret)   # To do machine learning
library(fastknn) # To fit a fast KNN model
library(ranger)  # To fit a fast Random Forest model
```

Here we will use the notation `package_name::function_name()` to make it easy to know the package that provides each function.

## Data Preprocessing

### Import Data

```{r}
adult <- readr::read_csv("adult.csv.zip", na = "?")
dplyr::glimpse(adult)
```

Now, let's check the class proportions:

```{r}
table(adult$income)
```

So, we have an **imbalanced classification** dataset.

### Select Variables

Here we will remove meaningless variables:

```{r}
dataset <- dplyr::select(adult, -fnlwgt, -capital.gain, -capital.loss)
```

### Transform Variables

Now, we will transform all `character` variables to `factor`, a more efficient format to represent categorical variables.

```{r}
chr.vars <- which(purrr::map_lgl(dataset, is.character))
dataset  <- dplyr::mutate_each(dataset, funs(as.factor), chr.vars)

## Compare object sizes
sprintf(
   "character size: %s; factor size: %s",
   format(object.size(adult$native.country), units = "KB"),
   format(object.size(dataset$native.country), units = "KB")
)
```

### Deal with Missing Values

The `adult` dataset has some missing values. More specifically:

```{r}
# Number of instances with missing values
sum(!complete.cases(adult))
```

The simplest way to impute missing values consists in replacing them with the `mean` or `median` for numerical variables and with the `mode` for categorical ones, as follows:

```{r}
na.fill <- purrr::map(dataset, function(column) {
   if (is.numeric(column)) {
      return(median(column))
   } else {
      column.tbl <- table(column)
      return(names(column.tbl)[which.max(column.tbl)])
   }
})
dataset <- tidyr::replace_na(dataset, replace = na.fill)
dplyr::glimpse(dataset)
```

Or we can just remove instances/observations with missing values:

```{r}
dataset <- na.omit(dataset)
```

## Exploratory Data Analysis

Let's explore the dataset and understand the patterns with the data before building any machine learning model.

### Hypothesis 1: People who are older earn more

The variable `age` is numeric, so we can check its distribution with respect to the `income` labels using a density plot:

```{r}
ggplot(dataset, aes(x = age, color = income, fill = income)) +
   geom_density(alpha = 0.8) +
   labs(x = "Age", y = "Density", title = "People who are older earn more",
        subtitle = "Density plot")
```

Or a boxplot:

```{r}
ggplot(dataset, aes(x = income, y = age, color = income)) +
   geom_boxplot(alpha = 0.8, outlier.shape = NA) +
   labs(x = "Income", y = "Age", title = "People who are older earn more",
        subtitle = "Box and whisker plot")
```

New let's estimate the central tendency for the `age` in both groups:

```{r}
dataset %>% 
   dplyr::group_by(income) %>% 
   dplyr::summarise(age = median(age))
```

So, people who earn above 50K tend to be aged around 44, while people who earn below 50K tend to be aged around 34.
